{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cup7/anaconda3/envs/analysis_framework_env/lib/python3.7/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['copy']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%pylab inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.rcParams['figure.figsize'] = (8, 6)\n",
    "matplotlib.rcParams.update({'font.size':16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dash_data_format(df, feature_list, target, regions, outfilename, region_column=\"app\"):\n",
    "#     feature_list_and_target = feature_list[:]\n",
    "    feature_list_and_target = feature_list[:]\n",
    "    feature_list_and_target.append(target)\n",
    "    \n",
    "    with open(outfilename, 'w') as txtfile:   \n",
    "        s = ','\n",
    "        s += ','.join([str(item) for item in regions])\n",
    "        s += '\\n'\n",
    "        txtfile.write(s)\n",
    "\n",
    "        for feat in feature_list_and_target:\n",
    "            if feat == region_column:\n",
    "                continue\n",
    "            row=feat# + \",\\\"\"\n",
    "            for reg in regions:\n",
    "                row += \",\\\"\"\n",
    "                ## GEt all rows that have the same kernel/region name\n",
    "                df_tmp = df[(df[region_column] == reg )] # DEBUG for empty values              \n",
    "                vals = []\n",
    "                \n",
    "                ## Now, make their values into a list\n",
    "                [vals.append(v) for v in df_tmp[feat].values]\n",
    "                s = ','.join([str(v) for v in vals])\n",
    "                row += s + \"\\\"\"\n",
    "            row += '\\n'\n",
    "            txtfile.write(row)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(var1, var2):\n",
    "    return (var1 / var2) ##This function can create an arbitrary combination of the two variables passed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from os import path\n",
    "import yaml\n",
    "\n",
    "def read_input_with_config():\n",
    "    input_prefix = ['/Users/tanzima/Research/AMD/DATA/mi-50/DATA-july21/rnn-bench-prof/']\n",
    "\n",
    "    #filelist = ['s30-b32-l128.csv', 's30-b128-l128.csv', 's30-b32-l512.csv', 's30-b128-l512.csv', 's30-b32-l1024.csv','s30-b128-l1024.csv']#, 'rnn/out-rnn-rnn-s30-b32-l128.csv']\n",
    "    config_file = 'tf_cnn_bench_config.yml'\n",
    "    workloads = dict()\n",
    "    \n",
    "    for arch in range(len(input_prefix)):\n",
    "        print('ARCH: ', arch, input_prefix[arch])\n",
    "        input_file_list = []\n",
    "        with open(input_prefix[arch]+config_file) as file: \n",
    "            config_file = yaml.load(file, Loader=yaml.FullLoader)\n",
    "#             print(config_file)\n",
    "            for configs in config_file:\n",
    "                print (configs)\n",
    "                for key in config_file[configs]:\n",
    "                    val = config_file[configs][key]\n",
    "                    if key == 'data':                        \n",
    "                        filename = input_prefix[arch] + val\n",
    "                        if path.exists(filename):\n",
    "                            input_file_list.append(filename)\n",
    "                            filename=\"\"\n",
    "                        else:\n",
    "                            print(filename, \"didn't exist\")\n",
    "        workloads[arch] = input_file_list\n",
    "    ##TODO: Change this\n",
    "    output_prefix = ['/Users/tanzima/Research/Stash/dashing-analysis-framework/data/gilgamesh/dash_format_tf_bench']\n",
    "\n",
    "    return workloads, output_prefix # target_list and filter_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Q2 DATA processing: TF_cnn workloads -- all models merged\n",
    "\n",
    "import os.path\n",
    "from os import path\n",
    "\n",
    "def read_input_manual():\n",
    "#     input_prefix = ['/Users/tanzima/Research/AMD/DATA/vega-20/basic_lstm/', '/Users/tanzima/Research/AMD/DATA/vega-20/rnn/']\n",
    "    input_prefix = ['/Users/tanzima/Research/AMD/DATA/mi-50/DATA-july21/rnn-bench-prof/prof-']\n",
    "\n",
    "    filelist = ['resnet50-imagenet-b16.csv', 'resnet50-imagenet-b32.csv', 'resnet50-imagenet-b64.csv', 'resnet50-imagenet-b128.csv',\n",
    "               'alexnet-imagenet-b16.csv', 'alexnet-imagenet-b32.csv', 'alexnet-imagenet-b64.csv', 'alexnet-imagenet-b128.csv',\n",
    "               'googlenet-imagenet-b16.csv', 'googlenet-imagenet-b32.csv', 'googlenet-imagenet-b64.csv', 'googlenet-imagenet-b128.csv',\n",
    "               'lenet-imagenet-b16.csv', 'lenet-imagenet-b32.csv', 'lenet-imagenet-b64.csv', 'lenet-imagenet-b128.csv']\n",
    "\n",
    "    workloads = dict()\n",
    "    \n",
    "    for arch in range(len(input_prefix)):\n",
    "        print('Model: ', arch, input_prefix[arch])\n",
    "        input_file_list = []\n",
    "        for ind in range(len(filelist)):\n",
    "            filename = input_prefix[arch] + filelist[ind]\n",
    "            print('IND: ', ind, filename)\n",
    "            if path.exists(filename):\n",
    "                input_file_list.append(filename)\n",
    "                filename=\"\"\n",
    "            else:\n",
    "                print(filename, \"didn't exist\")\n",
    "        workloads[arch] = input_file_list\n",
    "    ##TODO: Change this\n",
    "    output_prefix = ['/Users/tanzima/Research/Stash/dashing-analysis-framework/data/gilgamesh/dash_format_tf_cnn_combined']\n",
    "\n",
    "    return workloads, output_prefix # target_list and filter_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from os import path\n",
    "\n",
    "def read_input_manual1():\n",
    "#     input_prefix = ['/Users/tanzima/Research/AMD/DATA/vega-20/basic_lstm/', '/Users/tanzima/Research/AMD/DATA/vega-20/rnn/']\n",
    "    input_prefix = ['/Users/tanzima/Research/AMD/DATA/mi-50/Data-Apr21/lstm/']\n",
    "\n",
    "    filelist = ['s30-b32-l128.csv', 's30-b128-l128.csv', 's30-b32-l512.csv', 's30-b128-l512.csv', 's30-b32-l1024.csv','s30-b128-l1024.csv']#, 'rnn/out-rnn-rnn-s30-b32-l128.csv']\n",
    "\n",
    "    workloads = dict()\n",
    "    \n",
    "    for arch in range(len(input_prefix)):\n",
    "        print('ARCH: ', arch, input_prefix[arch])\n",
    "        input_file_list = []\n",
    "        for ind in range(len(filelist)):\n",
    "            filename = input_prefix[arch] + filelist[ind]\n",
    "            print('IND: ', ind, filename)\n",
    "            if path.exists(filename):\n",
    "                input_file_list.append(filename)\n",
    "                filename=\"\"\n",
    "            else:\n",
    "                print(filename, \"didn't exist\")\n",
    "        workloads[arch] = input_file_list\n",
    "    ##TODO: Change this\n",
    "    output_prefix = ['/Users/tanzima/Research/Stash/dashing-analysis-framework/data/gilgamesh/dash_format_lstm']\n",
    "\n",
    "    return workloads, output_prefix # target_list and filter_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Q2 DATA processing: TF_cnn workloads, each model separate, within each model all inputs merged.\n",
    "\n",
    "import os.path\n",
    "from os import path\n",
    "\n",
    "def read_input_manual2():\n",
    "#     input_prefix = ['/Users/tanzima/Research/AMD/DATA/vega-20/basic_lstm/', '/Users/tanzima/Research/AMD/DATA/vega-20/rnn/']\n",
    "    input_prefix = ['/Users/tanzima/Research/AMD/DATA/mi-50/DATA-july21/rnn-bench-prof/prof-resnet50-', \n",
    "                    '/Users/tanzima/Research/AMD/DATA/mi-50/DATA-july21/rnn-bench-prof/prof-alexnet-',\n",
    "                   '/Users/tanzima/Research/AMD/DATA/mi-50/DATA-july21/rnn-bench-prof/prof-googlenet-',\n",
    "                   '/Users/tanzima/Research/AMD/DATA/mi-50/DATA-july21/rnn-bench-prof/prof-lenet-']\n",
    "\n",
    "    filelist = ['imagenet-b16.csv', 'imagenet-b32.csv', 'imagenet-b64.csv', 'imagenet-b128.csv']\n",
    "\n",
    "    workloads = dict()\n",
    "    \n",
    "    for arch in range(len(input_prefix)):\n",
    "        print('Model: ', arch, input_prefix[arch])\n",
    "        input_file_list = []\n",
    "        for ind in range(len(filelist)):\n",
    "            filename = input_prefix[arch] + filelist[ind]\n",
    "            print('IND: ', ind, filename)\n",
    "            if path.exists(filename):\n",
    "                input_file_list.append(filename)\n",
    "                filename=\"\"\n",
    "            else:\n",
    "                print(filename, \"didn't exist\")\n",
    "        workloads[arch] = input_file_list\n",
    "    ##TODO: Change this\n",
    "    output_prefix = ['/Users/tanzima/Research/Stash/dashing-analysis-framework/data/gilgamesh/dash_format_resnet50',\n",
    "                    '/Users/tanzima/Research/Stash/dashing-analysis-framework/data/gilgamesh/dash_format_alexnet',\n",
    "                    '/Users/tanzima/Research/Stash/dashing-analysis-framework/data/gilgamesh/dash_format_googlenet',\n",
    "                    '/Users/tanzima/Research/Stash/dashing-analysis-framework/data/gilgamesh/dash_format_lenet']\n",
    "\n",
    "    return workloads, output_prefix # target_list and filter_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "################### AMD Q2: AAC data on MI-50\n",
    "import os.path\n",
    "from os import path\n",
    "\n",
    "def read_input_manual3(dir_prefix, modelname):\n",
    "#     input_prefix = ['/Users/tanzima/Research/AMD/DATA/vega-20/basic_lstm/', '/Users/tanzima/Research/AMD/DATA/vega-20/rnn/']\n",
    "    input_prefix = [dir_prefix+modelname+'/']#, \n",
    "#                    '/Users/tanzima/Research/AMD/DATA/mi-50/DATA-aac-july21/prof/basic_lstm/',\n",
    "#                    '/Users/tanzima/Research/AMD/DATA/mi-50/DATA-aac-july21/prof/rnn/']\n",
    "\n",
    "    filelist = ['s30-b32-l128.csv', 's30-b32-l512.csv', 's30-b32-l1024.csv', 's30-b128-l128.csv',  's30-b128-l512.csv', 's30-b128-l1024.csv']#, 'rnn/out-rnn-rnn-s30-b32-l128.csv']\n",
    "    \n",
    "    workloads = dict()\n",
    "    \n",
    "    for arch in range(len(input_prefix)):\n",
    "        # print('ARCH: ', arch, input_prefix[arch])\n",
    "        input_file_list = []\n",
    "        for ind in range(len(filelist)):\n",
    "            filename = input_prefix[arch] + filelist[ind]\n",
    "            print('IND: ', ind, filename)\n",
    "            if path.exists(filename):\n",
    "                input_file_list.append(filename)\n",
    "                filename=\"\"\n",
    "            else:\n",
    "                print(filename, \"didn't exist\")\n",
    "        workloads[arch] = input_file_list\n",
    "    ##TODO: Change this\n",
    "    output_prefix = ['/Users/tanzima/Research/Stash/dashing-analysis-framework/data/gilgamesh2/dash_format_aac_'+modelname]#,\n",
    "#                     '/Users/tanzima/Research/Stash/dashing-analysis-framework/data/gilgamesh/dash_format_aac_basic_lstm',\n",
    "#                     '/Users/tanzima/Research/Stash/dashing-analysis-framework/data/gilgamesh/dash_format_aac_rnn']\n",
    "\n",
    "    return workloads, output_prefix # target_list and filter_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "################### AMD Q2: AAC data on MI-100\n",
    "import os.path\n",
    "from os.path import isfile, join\n",
    "from os import path, listdir\n",
    "\n",
    "def read_input_manual9(input_dir, model_names): ####'/home/mohammad/analysis-framework/data/new_aac/', ['-basic_lstm-','-rnn-','-lstm-']\n",
    "    workloads = dict()\n",
    "\n",
    "    for ind in range(len(model_names)):\n",
    "        filelist = [join(input_dir,f) for f in listdir(input_dir) if f.endswith('.csv') and model_names[ind] in f]\n",
    "        workloads[ind] = filelist\n",
    "\n",
    "    output_prefix = []\n",
    "    for model in model_names:\n",
    "        # Add the desired path for the output, the system will automatically calculate the file name \n",
    "        output_prefix.append('/home/mohammad/aac_temp/dash_format_aac_mi100_' + model)\n",
    "\n",
    "    return workloads, output_prefix # target_list and filter_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from os.path import isfile, join\n",
    "from os import path, listdir\n",
    "\n",
    "def read_input_manual12(input_dir): ####'/home/mohammad/analysis-framework/data/new_aac/', ['-basic_lstm-','-rnn-','-lstm-']\n",
    "    workloads = dict()\n",
    "\n",
    "    filelist = [join(input_dir,f) for f in listdir(input_dir) if f.endswith('.csv')]\n",
    "    workloads[0] = filelist\n",
    "\n",
    "    output_prefix = []\n",
    "        # Add the desired path for the output, the system will automatically calculate the file name \n",
    "    output_prefix.append('/home/cup7/rawDatasets/gpu-bench/gpu-l2-cache/amdmi200/workloads/combinedworkloads')\n",
    "\n",
    "    return workloads, output_prefix # target_list and filter_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ['./amd_0.csv', './amd_5.csv', './amd_3.csv', './amd_6.csv', './amd_2.csv', './amd_1.csv']}\n"
     ]
    }
   ],
   "source": [
    "# workloads, output_prefix = read_input_with_config() #file_name_list\n",
    "# workloads, output_prefix = read_input_manual3('/Users/tanzima/Research/AMD/DATA/mi-50/DATA-aac-july21/prof/', 'rnn') #file_name_list\n",
    "# workloads, output_prefix = read_input_manual3('/Users/tanzima/Research/AMD/DATA/mi-50/DATA-aac-july21/prof/', 'lstm') #file_name_list\n",
    "# workloads, output_prefix = read_input_manual3('/Users/tanzima/Research/AMD/DATA/mi-50/DATA-aac-july21/prof/', 'basic_lstm') #file_name_list\n",
    "#workloads, output_prefix = read_input_manual3('/Users/tanzima/Research/AMD/DATA/mi-50/DATA-aac-july21/prof/', 'tf_cnn') #file_name_list\n",
    "\n",
    "# add path to the untar files and which model to analyze\n",
    "workloads, output_prefix = read_input_manual12('.') #file_name_list\n",
    "\n",
    "\n",
    "print(workloads)\n",
    "#print(pd.read_csv(workloads[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_list_parser(region_list):\n",
    "    for i, kernelName in enumerate(region_list):\n",
    "        templateIdx = kernelName.find(\"<\")\n",
    "        if templateIdx == -1:\n",
    "            continue\n",
    "        namespaceIdx = kernelName.rfind(\"::\", 0, templateIdx)\n",
    "        assert(namespaceIdx != -1) # Shouldn't ever happen.\n",
    "        region_list[i] = kernelName[namespaceIdx+2:templateIdx]\n",
    "    print(region_list)\n",
    "    return region_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_common_features_and_regions(df_dict_param, filter_list, region_column=\"app\"):\n",
    "    # df_dist: list of workloads within a model\n",
    "    # filter_list: columns (metrics/counters) we don't want\n",
    "\n",
    "    features_dict = defaultdict(int)\n",
    "    common_region_dict = defaultdict(int)\n",
    "    regions_list_with_dup = [] # \"region\" = kernel\n",
    "    feature_list = [] # \"feature\" = column (metric/counter)\n",
    "    \n",
    "    #For each file\n",
    "    for key, df_instance in df_dict_param.items():\n",
    "        #read in the file\n",
    "        df_original2 = df_instance.copy()\n",
    "        ## REMOVE all columns that contain only 0s\n",
    "        df_original2 = df_original2.loc[:, (df_original2 != 0).any(axis=0)]\n",
    "        for v in df_original2.columns:\n",
    "            features_dict[v] += 1\n",
    "            \n",
    "        for v in df_original2[region_column]:\n",
    "            common_region_dict[v] += 1\n",
    "            #regions_list_with_dup.append(v)\n",
    "            \n",
    "    ## Finding the unique names of regions since regions_list_with_dup may have duplicate region names.\n",
    "    ##Here, region == kernel\n",
    "#     region_list = list(set(regions_list_with_dup))\n",
    "\n",
    "    ## FINDING COMMON FEATURES\n",
    "    common_feature_list = []\n",
    "    for k, v in features_dict.items():\n",
    "        if k in filter_list:\n",
    "            continue\n",
    "        if v == len(df_dict_param):\n",
    "            common_feature_list.append(k)\n",
    "\n",
    "            \n",
    "    ## FINDING COMMON Regions\n",
    "    common_region_list = []\n",
    "    for k, v in common_region_dict.items():\n",
    "        if v == len(df_dict_param):\n",
    "            common_region_list.append(k)\n",
    "\n",
    "        \n",
    "    return common_feature_list, common_region_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ./amd_0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cup7/anaconda3/envs/analysis_framework_env/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/cup7/anaconda3/envs/analysis_framework_env/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/cup7/anaconda3/envs/analysis_framework_env/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/cup7/anaconda3/envs/analysis_framework_env/lib/python3.7/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ./amd_5.csv\n",
      "2 ./amd_3.csv\n",
      "3 ./amd_6.csv\n",
      "4 ./amd_2.csv\n",
      "5 ./amd_1.csv\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "## Reading and saving input\n",
    "df_dict_input = {}\n",
    "total_file_count = 0\n",
    "\n",
    "for ind in range(len(workloads)):\n",
    "    file_name_list = workloads[ind]\n",
    "    for fname in file_name_list:\n",
    "        if not path.exists(fname):\n",
    "            print(fname, ' does not exist....')\n",
    "            continue\n",
    "        else:\n",
    "            print(total_file_count, fname)\n",
    "            df_original2 = pd.read_csv(fname)\n",
    "\n",
    "            ######### New Formulas here ######################\n",
    "            df_original2['VALU_Util'] = 100 * (df_original2['SQ_ACTIVE_INST_VALU']/(df_original2['GRBM_GUI_ACTIVE'] * 104))\n",
    "            df_original2['GPU_Activity'] = (df_original2['GRBM_GUI_ACTIVE'] / df_original2['GRBM_COUNT']) * 100\n",
    "            df_original2['GPU_Occupancy'] = df_original2['SQ_ACCUM_PREV_HIRES'] / df_original2['GRBM_GUI_ACTIVE']\n",
    "            df_original2['SALU_Util'] = 100 * (df_original2['SQ_ACTIVE_INST_SCA']/(df_original2['GRBM_GUI_ACTIVE'] * 104))\n",
    "            df_original2['VALU_threads_per_wave_avg'] = df_original2['SQ_THREAD_CYCLES_VALU']/df_original2['SQ_ACTIVE_INST_VALU']\n",
    "\n",
    "\n",
    "            temp_df = df_original2.iloc[:math.ceil(df_original2.shape[0]/2),:]\n",
    "            temp_df2 = df_original2.iloc[math.floor(df_original2.shape[0]/2):,:]\n",
    "            temp_df2['KernelName']=[s.replace(',','_') for s in temp_df2['KernelName']]\n",
    "            temp_df['KernelName']=[s.replace(',','_') for s in temp_df['KernelName']]\n",
    "            temp_df2['KernelName']=[s.replace(' ','_') for s in temp_df2['KernelName']]\n",
    "            temp_df['KernelName']=[s.replace(' ','_') for s in temp_df['KernelName']]\n",
    "            del df_original2\n",
    "            temp_df = temp_df.groupby(['KernelName']).agg(func='mean')\n",
    "            temp_df2 = temp_df2.groupby(['KernelName']).agg(func='mean')\n",
    "#             print(temp_df2.columns)\n",
    "            temp_df = temp_df.append(temp_df2)\n",
    "            df_dict_input[total_file_count] = temp_df.groupby(['KernelName']).agg(func='mean')\n",
    "            df_dict_input[total_file_count] = df_dict_input[total_file_count].reset_index()\n",
    "            total_file_count += 1\n",
    "            del temp_df\n",
    "            del temp_df2\n",
    "print(total_file_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                          KernelName  Unnamed: 0  gpu-id  \\\n",
      "0  initKernel(HIP_vector_type<float__4u>*__unsign...       128.0     2.0   \n",
      "1  void_sumKernel<24__1024>(HIP_vector_type<float...       129.5     2.0   \n",
      "\n",
      "   queue-id  queue-index        pid        tid          grd     wgr  lds  ...  \\\n",
      "0       0.0        213.0  3453189.0  3453189.0      13312.0   256.0  0.0  ...   \n",
      "1       0.0        215.5  3453189.0  3453189.0  102400000.0  1024.0  0.0  ...   \n",
      "\n",
      "   TCC_EA_RDREQ_DRAM_CREDIT_STALL_std  TCC_EA_RDREQ_GMI_CREDIT_STALL_std  \\\n",
      "0                            0.000000                                0.0   \n",
      "1                        98097.430057                                0.0   \n",
      "\n",
      "   TCC_EA_RDREQ_IO_CREDIT_STALL_std  TCC_EA_RDREQ_LEVEL_std  TCC_EA_WRREQ_std  \\\n",
      "0                               0.0            9.195397e+02      3.241677e+07   \n",
      "1                               0.0            1.591569e+08      0.000000e+00   \n",
      "\n",
      "   TCC_EA_WRREQ_64B_std  TCC_EA_WRREQ_DRAM_CREDIT_STALL_std  \\\n",
      "0              0.294719                         3095.227727   \n",
      "1              0.000000                            0.000000   \n",
      "\n",
      "   TCC_EA_WRREQ_GMI_CREDIT_STALL_std  TCC_EA_WRREQ_IO_CREDIT_STALL_std  \\\n",
      "0                                0.0                               0.0   \n",
      "1                                0.0                               0.0   \n",
      "\n",
      "   TCC_EA_WRREQ_LEVEL_std  \n",
      "0            2.244031e+06  \n",
      "1            0.000000e+00  \n",
      "\n",
      "[2 rows x 329 columns],                                           KernelName  Unnamed: 0  gpu-id  \\\n",
      "0  initKernel(HIP_vector_type<float__4u>*__unsign...       128.0     2.0   \n",
      "1  void_sumKernel<24__1024>(HIP_vector_type<float...       129.5     2.0   \n",
      "\n",
      "   queue-id  queue-index        pid        tid          grd     wgr  lds  ...  \\\n",
      "0       0.0        213.0  3648736.0  3648736.0      13312.0   256.0  0.0  ...   \n",
      "1       0.0        215.5  3648736.0  3648736.0  102400000.0  1024.0  0.0  ...   \n",
      "\n",
      "   TCC_EA_WRREQ_std  TCC_EA_WRREQ_64B_std  TCC_EA_RDREQ_std  \\\n",
      "0      3.263766e+07              0.572086      9.241689e+02   \n",
      "1      0.000000e+00              0.000000      2.426026e+09   \n",
      "\n",
      "   TCC_EA_RDREQ_32B_std  TCC_EA_RDREQ_DRAM_CREDIT_STALL_std  \\\n",
      "0                   0.0                            0.000000   \n",
      "1                   0.0                       111558.399641   \n",
      "\n",
      "   TCC_EA_RDREQ_GMI_CREDIT_STALL_std  TCC_HIT_std  TCC_MISS_std  TCC_READ_std  \\\n",
      "0                                0.0     3.805978      0.555608      3.952313   \n",
      "1                                0.0  2152.306356   2641.946983   2195.909147   \n",
      "\n",
      "   TCC_REQ_std  \n",
      "0     3.974386  \n",
      "1  2195.909147  \n",
      "\n",
      "[2 rows x 329 columns],                                           KernelName  Unnamed: 0  gpu-id  \\\n",
      "0  initKernel(HIP_vector_type<float__4u>*__unsign...       128.0     2.0   \n",
      "1  void_sumKernel<24__1024>(HIP_vector_type<float...       129.5     2.0   \n",
      "\n",
      "   queue-id  queue-index        pid        tid          grd     wgr  lds  ...  \\\n",
      "0       0.0        213.0  3625287.0  3625287.0      13312.0   256.0  0.0  ...   \n",
      "1       0.0        215.5  3625287.0  3625287.0  102400000.0  1024.0  0.0  ...   \n",
      "\n",
      "   TCC_EA_WRREQ_std  TCC_EA_WRREQ_64B_std  TCC_EA_RDREQ_std  \\\n",
      "0      3.258162e+07              0.467594      1.050703e+03   \n",
      "1      2.482828e+01              4.730837      2.407653e+09   \n",
      "\n",
      "   TCC_EA_RDREQ_32B_std  TCC_EA_RDREQ_DRAM_CREDIT_STALL_std  \\\n",
      "0                   0.0                            0.000000   \n",
      "1                   0.0                       135276.584797   \n",
      "\n",
      "   TCC_EA_RDREQ_GMI_CREDIT_STALL_std  TCC_HIT_std  TCC_MISS_std  TCC_READ_std  \\\n",
      "0                                0.0     3.830514      0.965557      4.330525   \n",
      "1                                0.0  2163.126385   2327.697349    997.361997   \n",
      "\n",
      "   TCC_REQ_std  \n",
      "0     4.246595  \n",
      "1   997.361997  \n",
      "\n",
      "[2 rows x 329 columns],                                           KernelName  Unnamed: 0  gpu-id  \\\n",
      "0  initKernel(HIP_vector_type<float__4u>*__unsign...       128.0     2.0   \n",
      "1  void_sumKernel<24__1024>(HIP_vector_type<float...       129.5     2.0   \n",
      "\n",
      "   queue-id  queue-index        pid        tid          grd     wgr  lds  ...  \\\n",
      "0       0.0        213.0  3651447.0  3651447.0      13312.0   256.0  0.0  ...   \n",
      "1       0.0        215.5  3651447.0  3651447.0  102400000.0  1024.0  0.0  ...   \n",
      "\n",
      "   TCC_EA_WRREQ_GMI_CREDIT_STALL_std  TCC_EA_WRREQ_IO_CREDIT_STALL_std  \\\n",
      "0                                0.0                               0.0   \n",
      "1                                0.0                               0.0   \n",
      "\n",
      "   TCC_EA_WRREQ_LEVEL_std  TCC_ATOMIC_std  TCC_CYCLE_std  TCC_EA_ATOMIC_std  \\\n",
      "0            2.784265e+06             0.0            0.0                0.0   \n",
      "1            0.000000e+00             0.0            0.0                0.0   \n",
      "\n",
      "   TCC_EA_ATOMIC_LEVEL_std  TCC_RW_REQ_std  TCC_TOO_MANY_EA_WRREQS_STALL_std  \\\n",
      "0                      0.0        0.771574                               0.0   \n",
      "1                      0.0     1881.450714                               0.0   \n",
      "\n",
      "   TCC_WRITE_std  \n",
      "0       0.118140  \n",
      "1       0.209864  \n",
      "\n",
      "[2 rows x 329 columns],                                           KernelName  Unnamed: 0  gpu-id  \\\n",
      "0  initKernel(HIP_vector_type<float__4u>*__unsign...       128.0     2.0   \n",
      "1  void_sumKernel<24__1024>(HIP_vector_type<float...       129.5     2.0   \n",
      "\n",
      "   queue-id  queue-index        pid        tid          grd     wgr  lds  ...  \\\n",
      "0       0.0        213.0  3537246.0  3537246.0      13312.0   256.0  0.0  ...   \n",
      "1       0.0        215.5  3537246.0  3537246.0  102400000.0  1024.0  0.0  ...   \n",
      "\n",
      "   TCC_EA_WRREQ_GMI_CREDIT_STALL_std  TCC_EA_WRREQ_IO_CREDIT_STALL_std  \\\n",
      "0                                0.0                               0.0   \n",
      "1                                0.0                               0.0   \n",
      "\n",
      "   TCC_EA_WRREQ_LEVEL_std  TCC_ATOMIC_std  TCC_CYCLE_std  TCC_EA_ATOMIC_std  \\\n",
      "0            2.274945e+06             0.0            0.0                0.0   \n",
      "1            0.000000e+00             0.0            0.0                0.0   \n",
      "\n",
      "   TCC_EA_ATOMIC_LEVEL_std  TCC_RW_REQ_std  TCC_TOO_MANY_EA_WRREQS_STALL_std  \\\n",
      "0                      0.0        1.019129                               0.0   \n",
      "1                      0.0     1142.908074                               0.0   \n",
      "\n",
      "   TCC_WRITE_std  \n",
      "0       0.094512  \n",
      "1       0.394232  \n",
      "\n",
      "[2 rows x 329 columns],                                           KernelName  Unnamed: 0  gpu-id  \\\n",
      "0  initKernel(HIP_vector_type<float__4u>*__unsign...       128.0     2.0   \n",
      "1  void_sumKernel<24__1024>(HIP_vector_type<float...       129.5     2.0   \n",
      "\n",
      "   queue-id  queue-index        pid        tid          grd     wgr  lds  ...  \\\n",
      "0       0.0        213.0  3464456.0  3464456.0      13312.0   256.0  0.0  ...   \n",
      "1       0.0        215.5  3464456.0  3464456.0  102400000.0  1024.0  0.0  ...   \n",
      "\n",
      "   TCC_READ_std  TCC_REQ_std  TCC_EA_WRREQ_DRAM_CREDIT_STALL_std  \\\n",
      "0      4.025925     3.973139                         4246.478973   \n",
      "1   1340.434811  1340.478133                            0.000000   \n",
      "\n",
      "   TCC_EA_WRREQ_GMI_CREDIT_STALL_std  TCC_EA_WRREQ_IO_CREDIT_STALL_std  \\\n",
      "0                                0.0                               0.0   \n",
      "1                                0.0                               0.0   \n",
      "\n",
      "   TCC_EA_WRREQ_LEVEL_std  TCC_EA_RDREQ_IO_CREDIT_STALL_std  \\\n",
      "0            2.490514e+06                          6.149711   \n",
      "1            0.000000e+00                          0.000000   \n",
      "\n",
      "   TCC_EA_RDREQ_LEVEL_std  TCC_EA_WRREQ_std  TCC_EA_WRREQ_64B_std  \n",
      "0            2.533518e+03      3.281076e+07              0.399896  \n",
      "1            1.616504e+08      0.000000e+00              0.000000  \n",
      "\n",
      "[2 rows x 329 columns]]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "## save the df_dict.\n",
    "df_dict_copy = copy.deepcopy(df_dict_input)\n",
    "############## Calculating the standard deviation across indexed variables that are specific to channels.\n",
    "for wl_id, wl in df_dict_copy.items():\n",
    "    df2 = (pd.DataFrame.from_dict(wl)).filter(regex='\\[*\\]')#, orient='index', columns=['ColumnName']) \n",
    "    variables_with_indices = df2.columns\n",
    "    count = {}\n",
    "    base_varnames_list = []\n",
    "    for each_var in variables_with_indices:\n",
    "#         print(each_var.split('[')[0])\n",
    "        base_varname = each_var.split('[')[0]\n",
    "        if base_varname not in count:\n",
    "            count[base_varname] = 1\n",
    "            base_varnames_list.append(base_varname)\n",
    "        else:\n",
    "            count[base_varname] += 1\n",
    "#     print (count)\n",
    "#     wl.drop(variables_with_indices, inplace=True, axis=1)\n",
    "    new_wl = wl.drop(variables_with_indices, axis=1)\n",
    "#     print(new_wl.columns)\n",
    "    ## Add back computed distribution of the channeled variable\n",
    "    for each_base_varname in base_varnames_list:\n",
    "        df_each_base_varname = df2.filter(regex=each_base_varname)\n",
    "        #print(each_base_varname, df_each_base_varname.std(axis=1))\n",
    "        new_wl[each_base_varname+'_std'] = df_each_base_varname.std(axis=1)\n",
    "    df_dict_copy[wl_id] = copy.deepcopy(new_wl)\n",
    "\n",
    "print([v for c, v in df_dict_copy.items()])\n",
    "df_with_stdDev_vars = copy.deepcopy(df_dict_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for key, val in df_with_stdDev_vars.items():\n",
    "    print (key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['initKernel(HIP_vector_type<float__4u>*__unsigned_long)_', 'void_sumKernel<24__1024>(HIP_vector_type<float__4u>*__HIP_vector_type<float__4u>_const*__int)_']\n"
     ]
    }
   ],
   "source": [
    "## Input processing and finding common features, and create a list of data frames for each model.\n",
    "#target_list = ['score']\n",
    "\n",
    "## Create derived target metrics\n",
    "#For each file\n",
    "##MOVE target_list and filter_list to be a list that is returned from read_input\n",
    "# target_list = ['ts', 'GPUBusy', 'VALUBusy', 'MemUnitBusy', 'VALUUtilization', 'ratio1', 'ratio2']\n",
    "filter_list = ['BeginNs', 'EndNs', 'DispatchNs', 'BeginNs', 'EndNs', 'CompleteNs', 'Index','queue-id','queue-index', 'pid', 'tid', 'grd', 'wgr', 'lds', 'vgpr', 'sgpr', 'fbar', 'sig', 'obj']\n",
    "# filter_list = ['ID','Process ID','Process Name','Host Name','Context','Stream','Block Size','Grid Size','Device','CC','device__attribute_architecture','device__attribute_async_engine_count','device__attribute_can_flush_remote_writes','device__attribute_can_map_host_memory','device__attribute_can_tex2d_gather','device__attribute_can_use_64_bit_stream_mem_ops','device__attribute_can_use_64_bit_stream_mem_ops_v1','device__attribute_can_use_host_pointer_for_registered_mem','device__attribute_can_use_stream_mem_ops_v1','device__attribute_can_use_stream_wait_value_nor','device__attribute_can_use_stream_wait_value_nor_v1','device__attribute_chip','device__attribute_clock_rate','device__attribute_cluster_launch','device__attribute_compute_capability_major','device__attribute_compute_capability_minor','device__attribute_compute_mode','device__attribute_compute_preemption_supported','device__attribute_concurrent_kernels','device__attribute_concurrent_managed_access','device__attribute_cooperative_launch','device__attribute_cooperative_multi_device_launch','device__attribute_deferred_mapping_cuda_array_supported','device__attribute_device_index','device__attribute_direct_managed_mem_access_from_host','device__attribute_display_name','device__attribute_dma_buf_supported','device__attribute_ecc_enabled','device__attribute_fb_bus_width','device__attribute_fbp_count','device__attribute_generic_compression_supported','device__attribute_global_l1_cache_supported','device__attribute_global_memory_bus_width','device__attribute_gpu_direct_rdma_flush_writes_options','device__attribute_gpu_direct_rdma_supported','device__attribute_gpu_direct_rdma_with_cuda_vmm_supported','device__attribute_gpu_direct_rdma_writes_ordering','device__attribute_gpu_overlap','device__attribute_gpu_pci_device_id','device__attribute_gpu_pci_ext_device_id','device__attribute_gpu_pci_ext_downstream_link_rate','device__attribute_gpu_pci_ext_downstream_link_width','device__attribute_gpu_pci_ext_gen','device__attribute_gpu_pci_ext_gpu_gen','device__attribute_gpu_pci_ext_gpu_link_rate','device__attribute_gpu_pci_ext_gpu_link_width','device__attribute_gpu_pci_revision_id','device__attribute_gpu_pci_sub_system_id','device__attribute_handle_type_posix_file_descriptor_supported','device__attribute_handle_type_win32_handle_supported','device__attribute_handle_type_win32_kmt_handle_supported','device__attribute_host_native_atomic_supported','device__attribute_host_register_supported','device__attribute_implementation','device__attribute_integrated','device__attribute_ipc_event_supported','device__attribute_kernel_exec_timeout','device__attribute_l2_cache_size','device__attribute_l2s_count','device__attribute_limits_max_cta_per_sm','device__attribute_local_l1_cache_supported','device__attribute_managed_memory','device__attribute_max_access_policy_window_size','device__attribute_max_block_dim_x','device__attribute_max_block_dim_y','device__attribute_max_block_dim_z','device__attribute_max_blocks_per_multiprocessor','device__attribute_max_gpu_frequency_khz','device__attribute_max_grid_dim_x','device__attribute_max_grid_dim_y','device__attribute_max_grid_dim_z','device__attribute_max_ipc_per_multiprocessor','device__attribute_max_ipc_per_scheduler','device__attribute_max_mem_frequency_khz','device__attribute_max_persisting_l2_cache_size','device__attribute_max_pitch','device__attribute_max_registers_per_block','device__attribute_max_registers_per_multiprocessor','device__attribute_max_registers_per_thread','device__attribute_max_shared_memory_per_block','device__attribute_max_shared_memory_per_block_optin','device__attribute_max_shared_memory_per_multiprocessor','device__attribute_max_threads_per_block','device__attribute_max_threads_per_multiprocessor','device__attribute_max_warps_per_multiprocessor','device__attribute_max_warps_per_scheduler','device__attribute_maximum_surface1d_layered_layers','device__attribute_maximum_surface1d_layered_width','device__attribute_maximum_surface1d_width','device__attribute_maximum_surface2d_height','device__attribute_maximum_surface2d_layered_height','device__attribute_maximum_surface2d_layered_layers','device__attribute_maximum_surface2d_layered_width','device__attribute_maximum_surface2d_width','device__attribute_maximum_surface3d_depth','device__attribute_maximum_surface3d_height','device__attribute_maximum_surface3d_width','device__attribute_maximum_surfacecubemap_layered_layers','device__attribute_maximum_surfacecubemap_layered_width','device__attribute_maximum_surfacecubemap_width','device__attribute_maximum_texture1d_layered_layers','device__attribute_maximum_texture1d_layered_width','device__attribute_maximum_texture1d_linear_width','device__attribute_maximum_texture1d_mipmapped_width','device__attribute_maximum_texture1d_width','device__attribute_maximum_texture2d_gather_height','device__attribute_maximum_texture2d_gather_width','device__attribute_maximum_texture2d_height','device__attribute_maximum_texture2d_layered_height','device__attribute_maximum_texture2d_layered_layers','device__attribute_maximum_texture2d_layered_width','device__attribute_maximum_texture2d_linear_height','device__attribute_maximum_texture2d_linear_pitch','device__attribute_maximum_texture2d_linear_width','device__attribute_maximum_texture2d_mipmapped_height','device__attribute_maximum_texture2d_mipmapped_width','device__attribute_maximum_texture2d_width','device__attribute_maximum_texture3d_depth','device__attribute_maximum_texture3d_depth_alternate','device__attribute_maximum_texture3d_height','device__attribute_maximum_texture3d_height_alternate','device__attribute_maximum_texture3d_width','device__attribute_maximum_texture3d_width_alternate','device__attribute_maximum_texturecubemap_layered_layers','device__attribute_maximum_texturecubemap_layered_width','device__attribute_maximum_texturecubemap_width','device__attribute_mem_sync_domain_count','device__attribute_memory_clock_rate','device__attribute_memory_pools_supported','device__attribute_mempool_supported_handle_types','device__attribute_multi_gpu_board','device__attribute_multi_gpu_board_group_id','device__attribute_multiprocessor_count','device__attribute_num_l2s_per_fbp','device__attribute_num_schedulers_per_multiprocessor','device__attribute_num_tex_per_multiprocessor','device__attribute_pageable_memory_access','device__attribute_pageable_memory_access_uses_host_page_tables','device__attribute_pci_bus_id','device__attribute_pci_device_id','device__attribute_pci_domain_id','device__attribute_ram_location','device__attribute_ram_type','device__attribute_reserved_shared_memory_per_block','device__attribute_sass_level','device__attribute_single_to_double_precision_perf_ratio','device__attribute_sparse_cuda_array_supported','device__attribute_stream_priorities_supported','device__attribute_surface_alignment','device__attribute_tcc_driver','device__attribute_tensor_map_access_supported','device__attribute_texture_alignment','device__attribute_texture_pitch_alignment','device__attribute_total_constant_memory','device__attribute_total_memory','device__attribute_unified_addressing','device__attribute_unified_function_pointers','device__attribute_virtual_address_management_supported','device__attribute_warp_size',\n",
    "#                'idc__request_cycles_active.avg.pct_of_peak_sustained_elapsed', 'l1tex__data_pipe_tex_wavefronts.avg.pct_of_peak_sustained_elapsed',\n",
    "#                'launch__block_dim_x','launch__block_dim_y','launch__block_dim_z','launch__block_size','launch__context_id','launch__device_id','launch__func_cache_config','launch__function_pcs','launch__grid_dim_x','launch__grid_dim_y','launch__grid_dim_z','launch__grid_size','launch__occupancy_limit_blocks','launch__occupancy_limit_registers','launch__occupancy_limit_shared_mem','launch__occupancy_limit_warps','launch__occupancy_per_block_size','launch__occupancy_per_register_count','launch__occupancy_per_shared_mem_size',\n",
    "#                'launch__shared_mem_config_size','launch__shared_mem_per_block','launch__shared_mem_per_block_allocated','launch__shared_mem_per_block_driver','launch__shared_mem_per_block_dynamic','launch__shared_mem_per_block_static','launch__stream_id','launch__thread_count','launch__uses_cdp','launch__waves_per_multiprocessor','lts__d_atomic_input_cycles_active.avg.pct_of_peak_sustained_elapsed',\n",
    "#                'numa__cpu_affinity','numa__dev_display_name_all','numa__id_cpu','numa__id_memory','nvlink__bandwidth','nvlink__count_logical','nvlink__count_physical','nvlink__destination_ports','nvlink__dev0Id','nvlink__dev0type','nvlink__dev1Id','nvlink__dev1type','nvlink__dev_display_name_all','nvlink__enabled_mask','nvlink__is_direct_link','nvlink__is_nvswitch_connected','nvlink__max_count','nvlink__peer_access','nvlink__peer_atomic','nvlink__source_ports','nvlink__system_access','nvlink__system_atomic','profiler__perfworks_session_reuse','profiler__replayer_passes','profiler__replayer_passes_type_warmup'\n",
    "#                 'sm__inst_executed_pipe_fp16.avg.pct_of_peak_sustained_elapsed','sm__inst_executed_pipe_ipa.avg.pct_of_peak_sustained_elapsed',\n",
    "#                'sm__inst_executed_pipe_tex.avg.pct_of_peak_sustained_elapsed', 'sm__inst_executed_pipe_xu.avg.pct_of_peak_sustained_elapsed',\n",
    "#                'sm__maximum_warps_avg_per_active_cycle', 'sm__pipe_fp64_cycles_active.avg.pct_of_peak_sustained_elapsed',\n",
    "#                'smsp__maximum_warps_avg_per_active_cycle',\n",
    "#               ]\n",
    "target_list = ['runtime']\n",
    "###### Decide which input dictionary we want to use, the one with stdDev variables or individual channels?\n",
    "\n",
    "# selected_df_dict = copy.deepcopy(df_dict_input)\n",
    "selected_df_dict = copy.deepcopy(df_with_stdDev_vars)\n",
    "\n",
    "\n",
    "common_top_region_list = []\n",
    "df_dict_updated = {}\n",
    "cumulative_workload_id = 0\n",
    "feature_list = {} ######### CHECK\n",
    "region_list = {} ################### CHECK\n",
    "shorten_region_list = {} ################### CHECK\n",
    "model_index = 0  # wot\n",
    "for model_index in range(len(workloads)): #For each model\n",
    "    \n",
    "    df_subdir = {}\n",
    "    for wl in range(len(workloads[model_index])): #For each input parameter in a model\n",
    "        df_subdir[wl] = selected_df_dict[cumulative_workload_id].copy()\n",
    "        cumulative_workload_id += 1\n",
    "    #Find the common regions and features. Should be consistent within a model.\n",
    "    ## TODO: Make a dictionary of feature list per model\n",
    "    feature_list[model_index], region_list[model_index] = find_common_features_and_regions(df_subdir, filter_list, \"KernelName\")\n",
    "#     shorten_region_list[model_index] = region_list_parser(region_list[model_index].copy())\n",
    "    shorten_region_list[model_index] = region_list[model_index]\n",
    "    \n",
    "    cumulative_df = pd.DataFrame(columns=feature_list[model_index])\n",
    "    \n",
    "    for wl in range(len(workloads[model_index])): #For each input parameter in a model\n",
    "        #read in the file\n",
    "        df_original2 = df_subdir[wl].copy() #The dataset is already there. \n",
    "        ## REMOVE all columns that contain only 0s\n",
    "        df_original2 = df_original2.loc[:, (df_original2 != 0).any(axis=0)]\n",
    "\n",
    "        #Add new targets-- for AMD work, the target 'ts' is computed based on 'BeginNs', 'EndNs'\n",
    "#         df_original2['ts'] = df_original2['EndNs'] - df_original2['BeginNs']\n",
    "#         df_original2['ratio1'] = 100*df_original2['VALUBusy'] / df_original2['GPUBusy'] #100*df_original2['GRBM_GUI_ACTIVE']/df_original2['GRBM_COUNT']\n",
    "#         df_original2['ratio2'] = 100*df_original2['VALUBusy'] / df_original2['MemUnitBusy'] #100*df_original2['GRBM_GUI_ACTIVE']/df_original2['GRBM_COUNT']\n",
    "#         df_original2['shortenKernel Name'] = #region_list_parser(df_original2['Kernel Name'].copy())#region_list[model_index].copy())\n",
    "        \n",
    "        ## Just keep the top 5 regions according to their 'ts'\n",
    "#         df_original2.sort_values(by=['ts'], inplace=True, ascending=False)\n",
    "        \n",
    "        ## Only keep those rows that belong to the common region names\n",
    "#         for reg in shorten_region_list[model_index]:\n",
    "#             df_original2 = df_original2[(df_original2['shortenKernel Name'] == reg )] \n",
    "        \n",
    "        ## Now, among those common regions, choose top 15 kernels.\n",
    "#         top_regions = (df_original2.head(15))['Kernel Name']\n",
    "#         region_list = top_regions\n",
    "        ## Now, create a list with the top kernel names \n",
    "        common_top_region_list.append([reg for reg in region_list[model_index]])\n",
    "\n",
    "        \n",
    "        # Now, appending all rows from different workloads to a stack workloads. Concat seems to be the way.\n",
    "        cumulative_df = cumulative_df.append(df_original2, ignore_index = True)\n",
    "#         print(wl, df_original2['MemUnitBusy'])        \n",
    "\n",
    "    df_dict_updated[model_index] = cumulative_df\n",
    "        \n",
    "        \n",
    "# for numx in df_dict_updated[0]['MemUnitBusy']: \n",
    "#     print(len(df_dict_updated[0]['MemUnitBusy']), numx)\n",
    "\n",
    "# print(common_top_region_list[0])\n",
    "common_region_list = list(set(common_top_region_list[0]))\n",
    "print(common_region_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating /home/cup7/rawDatasets/gpu-bench/gpu-l2-cache/amdmi200/workloads/combinedworkloads_runtime.csv...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "## Input processing and finding common features\n",
    "\n",
    "#target_list = ['score']\n",
    "\n",
    "## Create derived target metrics\n",
    "#For each file\n",
    "# target_list = ['ts', 'GPUBusy', 'VALUBusy', 'MemUnitBusy', 'VALUUtilization', 'ratio1', 'ratio2']\n",
    "# config_list = ['basic_lstm', 'lstm', 'rnn']\n",
    "# filter_list = ['ID','Process ID','Process Name','Host Name','Context','Stream','Block Size','Grid Size','Device','CC','device__attribute_architecture','device__attribute_async_engine_count','device__attribute_can_flush_remote_writes','device__attribute_can_map_host_memory','device__attribute_can_tex2d_gather','device__attribute_can_use_64_bit_stream_mem_ops','device__attribute_can_use_64_bit_stream_mem_ops_v1','device__attribute_can_use_host_pointer_for_registered_mem','device__attribute_can_use_stream_mem_ops_v1','device__attribute_can_use_stream_wait_value_nor','device__attribute_can_use_stream_wait_value_nor_v1','device__attribute_chip','device__attribute_clock_rate','device__attribute_cluster_launch','device__attribute_compute_capability_major','device__attribute_compute_capability_minor','device__attribute_compute_mode','device__attribute_compute_preemption_supported','device__attribute_concurrent_kernels','device__attribute_concurrent_managed_access','device__attribute_cooperative_launch','device__attribute_cooperative_multi_device_launch','device__attribute_deferred_mapping_cuda_array_supported','device__attribute_device_index','device__attribute_direct_managed_mem_access_from_host','device__attribute_display_name','device__attribute_dma_buf_supported','device__attribute_ecc_enabled','device__attribute_fb_bus_width','device__attribute_fbp_count','device__attribute_generic_compression_supported','device__attribute_global_l1_cache_supported','device__attribute_global_memory_bus_width','device__attribute_gpu_direct_rdma_flush_writes_options','device__attribute_gpu_direct_rdma_supported','device__attribute_gpu_direct_rdma_with_cuda_vmm_supported','device__attribute_gpu_direct_rdma_writes_ordering','device__attribute_gpu_overlap','device__attribute_gpu_pci_device_id','device__attribute_gpu_pci_ext_device_id','device__attribute_gpu_pci_ext_downstream_link_rate','device__attribute_gpu_pci_ext_downstream_link_width','device__attribute_gpu_pci_ext_gen','device__attribute_gpu_pci_ext_gpu_gen','device__attribute_gpu_pci_ext_gpu_link_rate','device__attribute_gpu_pci_ext_gpu_link_width','device__attribute_gpu_pci_revision_id','device__attribute_gpu_pci_sub_system_id','device__attribute_handle_type_posix_file_descriptor_supported','device__attribute_handle_type_win32_handle_supported','device__attribute_handle_type_win32_kmt_handle_supported','device__attribute_host_native_atomic_supported','device__attribute_host_register_supported','device__attribute_implementation','device__attribute_integrated','device__attribute_ipc_event_supported','device__attribute_kernel_exec_timeout','device__attribute_l2_cache_size','device__attribute_l2s_count','device__attribute_limits_max_cta_per_sm','device__attribute_local_l1_cache_supported','device__attribute_managed_memory','device__attribute_max_access_policy_window_size','device__attribute_max_block_dim_x','device__attribute_max_block_dim_y','device__attribute_max_block_dim_z','device__attribute_max_blocks_per_multiprocessor','device__attribute_max_gpu_frequency_khz','device__attribute_max_grid_dim_x','device__attribute_max_grid_dim_y','device__attribute_max_grid_dim_z','device__attribute_max_ipc_per_multiprocessor','device__attribute_max_ipc_per_scheduler','device__attribute_max_mem_frequency_khz','device__attribute_max_persisting_l2_cache_size','device__attribute_max_pitch','device__attribute_max_registers_per_block','device__attribute_max_registers_per_multiprocessor','device__attribute_max_registers_per_thread','device__attribute_max_shared_memory_per_block','device__attribute_max_shared_memory_per_block_optin','device__attribute_max_shared_memory_per_multiprocessor','device__attribute_max_threads_per_block','device__attribute_max_threads_per_multiprocessor','device__attribute_max_warps_per_multiprocessor','device__attribute_max_warps_per_scheduler','device__attribute_maximum_surface1d_layered_layers','device__attribute_maximum_surface1d_layered_width','device__attribute_maximum_surface1d_width','device__attribute_maximum_surface2d_height','device__attribute_maximum_surface2d_layered_height','device__attribute_maximum_surface2d_layered_layers','device__attribute_maximum_surface2d_layered_width','device__attribute_maximum_surface2d_width','device__attribute_maximum_surface3d_depth','device__attribute_maximum_surface3d_height','device__attribute_maximum_surface3d_width','device__attribute_maximum_surfacecubemap_layered_layers','device__attribute_maximum_surfacecubemap_layered_width','device__attribute_maximum_surfacecubemap_width','device__attribute_maximum_texture1d_layered_layers','device__attribute_maximum_texture1d_layered_width','device__attribute_maximum_texture1d_linear_width','device__attribute_maximum_texture1d_mipmapped_width','device__attribute_maximum_texture1d_width','device__attribute_maximum_texture2d_gather_height','device__attribute_maximum_texture2d_gather_width','device__attribute_maximum_texture2d_height','device__attribute_maximum_texture2d_layered_height','device__attribute_maximum_texture2d_layered_layers','device__attribute_maximum_texture2d_layered_width','device__attribute_maximum_texture2d_linear_height','device__attribute_maximum_texture2d_linear_pitch','device__attribute_maximum_texture2d_linear_width','device__attribute_maximum_texture2d_mipmapped_height','device__attribute_maximum_texture2d_mipmapped_width','device__attribute_maximum_texture2d_width','device__attribute_maximum_texture3d_depth','device__attribute_maximum_texture3d_depth_alternate','device__attribute_maximum_texture3d_height','device__attribute_maximum_texture3d_height_alternate','device__attribute_maximum_texture3d_width','device__attribute_maximum_texture3d_width_alternate','device__attribute_maximum_texturecubemap_layered_layers','device__attribute_maximum_texturecubemap_layered_width','device__attribute_maximum_texturecubemap_width','device__attribute_mem_sync_domain_count','device__attribute_memory_clock_rate','device__attribute_memory_pools_supported','device__attribute_mempool_supported_handle_types','device__attribute_multi_gpu_board','device__attribute_multi_gpu_board_group_id','device__attribute_multiprocessor_count','device__attribute_num_l2s_per_fbp','device__attribute_num_schedulers_per_multiprocessor','device__attribute_num_tex_per_multiprocessor','device__attribute_pageable_memory_access','device__attribute_pageable_memory_access_uses_host_page_tables','device__attribute_pci_bus_id','device__attribute_pci_device_id','device__attribute_pci_domain_id','device__attribute_ram_location','device__attribute_ram_type','device__attribute_reserved_shared_memory_per_block','device__attribute_sass_level','device__attribute_single_to_double_precision_perf_ratio','device__attribute_sparse_cuda_array_supported','device__attribute_stream_priorities_supported','device__attribute_surface_alignment','device__attribute_tcc_driver','device__attribute_tensor_map_access_supported','device__attribute_texture_alignment','device__attribute_texture_pitch_alignment','device__attribute_total_constant_memory','device__attribute_total_memory','device__attribute_unified_addressing','device__attribute_unified_function_pointers','device__attribute_virtual_address_management_supported','device__attribute_warp_size',\n",
    "#                'idc__request_cycles_active.avg.pct_of_peak_sustained_elapsed', 'l1tex__data_pipe_tex_wavefronts.avg.pct_of_peak_sustained_elapsed',\n",
    "#                'launch__block_dim_x','launch__block_dim_y','launch__block_dim_z','launch__block_size','launch__context_id','launch__device_id','launch__func_cache_config','launch__function_pcs','launch__grid_dim_x','launch__grid_dim_y','launch__grid_dim_z','launch__grid_size','launch__occupancy_limit_blocks','launch__occupancy_limit_registers','launch__occupancy_limit_shared_mem','launch__occupancy_limit_warps','launch__occupancy_per_block_size','launch__occupancy_per_register_count','launch__occupancy_per_shared_mem_size',\n",
    "#                'launch__shared_mem_config_size','launch__shared_mem_per_block','launch__shared_mem_per_block_allocated','launch__shared_mem_per_block_driver','launch__shared_mem_per_block_dynamic','launch__shared_mem_per_block_static','launch__stream_id','launch__thread_count','launch__uses_cdp','launch__waves_per_multiprocessor','lts__d_atomic_input_cycles_active.avg.pct_of_peak_sustained_elapsed',\n",
    "#                'numa__cpu_affinity','numa__dev_display_name_all','numa__id_cpu','numa__id_memory','nvlink__bandwidth','nvlink__count_logical','nvlink__count_physical','nvlink__destination_ports','nvlink__dev0Id','nvlink__dev0type','nvlink__dev1Id','nvlink__dev1type','nvlink__dev_display_name_all','nvlink__enabled_mask','nvlink__is_direct_link','nvlink__is_nvswitch_connected','nvlink__max_count','nvlink__peer_access','nvlink__peer_atomic','nvlink__source_ports','nvlink__system_access','nvlink__system_atomic','profiler__perfworks_session_reuse','profiler__replayer_passes','profiler__replayer_passes_type_warmup'\n",
    "#                 'sm__inst_executed_pipe_fp16.avg.pct_of_peak_sustained_elapsed','sm__inst_executed_pipe_ipa.avg.pct_of_peak_sustained_elapsed',\n",
    "#                'sm__inst_executed_pipe_tex.avg.pct_of_peak_sustained_elapsed', 'sm__inst_executed_pipe_xu.avg.pct_of_peak_sustained_elapsed',\n",
    "#                'sm__maximum_warps_avg_per_active_cycle', 'sm__pipe_fp64_cycles_active.avg.pct_of_peak_sustained_elapsed',\n",
    "#                'smsp__maximum_warps_avg_per_active_cycle',\n",
    "#               ]\n",
    "target_list = ['runtime']\n",
    "# target_list = ['ts']\n",
    "cumulative_index = 0\n",
    "for model_index in range(len(df_dict_updated)):#range(len(workloads)): #For each model\n",
    "    df_original2 = df_dict_updated[model_index]\n",
    "    for target in target_list:\n",
    "        df_original3 = df_original2[feature_list[model_index]]\n",
    "        ##Make sure to fill up all Nan values with 0\n",
    "        df_original3 = df_original3.fillna(0)\n",
    "\n",
    "        #Add a target at a time to original3\n",
    "        df_original3[target] = df_original2[target]\n",
    "\n",
    "        outfilename = output_prefix[model_index] + '_' + target+'.csv'\n",
    "        print('Generating ' + outfilename + '...')\n",
    "        #generate_dash_data_format(df_original3, feature_list, target, region_list, outfilename, \"KernelName\")\n",
    "        ## TODO: PASS the following function feature_list[ind] and region_list[ind]\n",
    "        generate_dash_data_format(df_original3, feature_list[model_index], target, region_list[model_index], outfilename, \"KernelName\")\n",
    "        \n",
    "        #generate_config_block_for_this_input(config_list[model_index] + '_'+target, outfilename, target)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'VALUBusy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/analysis_framework_env/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/analysis_framework_env/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/analysis_framework_env/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'VALUBusy'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_298011/429446518.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m#Add new targets-- for AMD work, the target 'ts' is computed based on 'BeginNs', 'EndNs'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mdf_original2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ts'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_original2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'EndNs'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdf_original2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'BeginNs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mdf_original2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ratio1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdf_original2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'VALUBusy'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdf_original2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'GPUBusy'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#100*df_original2['GRBM_GUI_ACTIVE']/df_original2['GRBM_COUNT']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mdf_original2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ratio2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdf_original2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'VALUBusy'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdf_original2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MemUnitBusy'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#100*df_original2['GRBM_GUI_ACTIVE']/df_original2['GRBM_COUNT']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/analysis_framework_env/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/analysis_framework_env/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'VALUBusy'"
     ]
    }
   ],
   "source": [
    "########## AMD Q2 block-- generate 1 dash file per input config or Workload. This is so that we can correlate the resource\n",
    "#### importance values with FOM\n",
    "\n",
    "##MOVE target_list and filter_list to be a list that is returned from read_input\n",
    "target_list = ['ts', 'GPUBusy', 'VALUBusy', 'MemUnitBusy', 'VALUUtilization', 'ratio1', 'ratio2']\n",
    "filter_list = ['BeginNs', 'EndNs', 'DispatchNs', 'BeginNs', 'EndNs', 'CompleteNs', 'Index','queue-id','queue-index', 'pid', 'tid', 'grd', 'wgr', 'lds', 'vgpr', 'sgpr', 'fbar', 'sig', 'obj']\n",
    "\n",
    "###### Decide which input dictionary we want to use, the one with stdDev variables or individual channels?\n",
    "\n",
    "# selected_df_dict = copy.deepcopy(df_dict_input)\n",
    "selected_df_dict = copy.deepcopy(df_with_stdDev_vars)\n",
    "df_subdir = {}\n",
    "df_dict_updated = {}\n",
    "cumulative_workload_id = 0\n",
    "feature_list = {} ######### CHECK\n",
    "region_list = {} ################### CHECK\n",
    "shorten_region_list = {} ################### CHECK\n",
    "\n",
    "\n",
    "for model_index in range(len(workloads)): #For each model lstm, basic_lstm, rnn, ....\n",
    "    for wl in range(len(workloads[model_index])): #For each input parameter in a model\n",
    "        df_subdir[wl] = selected_df_dict[cumulative_workload_id].copy()\n",
    "        feature_list[wl], region_list[wl] = find_common_features_and_regions(df_subdir, filter_list, \"KernelName\")\n",
    "        shorten_region_list[wl] = region_list[wl]\n",
    "\n",
    "        df_original2 = df_subdir[wl].copy() #The dataset is already there. \n",
    "        ## REMOVE all columns that contain only 0s\n",
    "        df_original2 = df_original2.loc[:, (df_original2 != 0).any(axis=0)]\n",
    "\n",
    "        #Add new targets-- for AMD work, the target 'ts' is computed based on 'BeginNs', 'EndNs'\n",
    "        df_original2['ts'] = df_original2['EndNs'] - df_original2['BeginNs']\n",
    "        df_original2['ratio1'] = 100*df_original2['VALUBusy'] / df_original2['GPUBusy'] #100*df_original2['GRBM_GUI_ACTIVE']/df_original2['GRBM_COUNT']\n",
    "        df_original2['ratio2'] = 100*df_original2['VALUBusy'] / df_original2['MemUnitBusy'] #100*df_original2['GRBM_GUI_ACTIVE']/df_original2['GRBM_COUNT']\n",
    "\n",
    "        #generate_dash_data_format(df_original2, feature_list[wl], \"ts\", region_list[wl], \"sample_dash.csv\", \"KernelName\")\n",
    "        df_dict_updated[cumulative_workload_id] = df_original2#.deepcopy()\n",
    "\n",
    "        cumulative_workload_id += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (df_dict_updated[0]['MemUnitBusy'], df_dict_updated[0]['MemUnitBusy'])\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (df_dict_input[0]['MemUnitBusy'], df_dict_input[0]['MemUnitBusy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in range(len(workloads)):\n",
    "    print(region_list)\n",
    "len(region_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in df_dict_updated.items():\n",
    "    print(len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#create two DataFrames\n",
    "\n",
    "df1 = pd.DataFrame({'player': ['A', 'B', 'A', 'B', 'B'],\n",
    "                    'points':[12, 5, 13, 17, 27],\n",
    "                   'extra':[1, 5, 3, 7, 2]})\n",
    "\n",
    "df2 = pd.DataFrame({'player': ['F', 'G', 'H', 'I', 'J'],\n",
    "                    'points':[24, 26, 27, 27, 12]})\n",
    "\n",
    "#\"stack\" the two DataFrames together\n",
    "df3 = pd.concat([df1,df2], axis=0, ignore_index=True)\n",
    "\n",
    "print (df1)\n",
    "# A = df1.append(df2, ignore_index=True)\n",
    "# print(A.append(df3, ignore_index=True))\n",
    "\n",
    "# df = df1.groupby(['player']).agg({'extra':'mean','points':'mean'})\n",
    "df = df1.groupby(['player']).agg(func='mean')\n",
    "df = df.reset_index()\n",
    "print (df)\n",
    "\n",
    "# print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generate_dash_data_format(df_dict_updated[0], feature_list[0], \"ts\", region_list[0], \"sample_dash.csv\", \"KernelName\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_dict_updated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_config_block_for_this_input(config_name, datafilename, target):\n",
    "    print(config_name + ':')\n",
    "    print('    data: ', datafilename)\n",
    "    print('    tasks: ')\n",
    "    print('      - modules.resource_score.compute_rsm_task_all_regions')\n",
    "    print('      - viz.barchart.create_rsm_error_barchart')\n",
    "    print('      - viz.barchart.create_rsm_percent_barchart')\n",
    "    print('      - viz.sunburst2.sunburst')\n",
    "    print('      - viz.linechart3.plot_raw_target_values')\n",
    "    print('      - viz.linechart3.raw_values_per_config')\n",
    "    print('    name: ', target)\n",
    "    print('    target: ', target)\n",
    "    \n",
    "    if target == 'ts':\n",
    "        print('    compute_target: modules.compute_target.compute_runtime')\n",
    "    else:\n",
    "        print('    compute_target: modules.compute_target.compute_inverse_target')\n",
    "    print('##############################')\n",
    "   \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## AMD Q2: OUTPUT PROESSING: 1 file per input per model.\n",
    "\n",
    "#target_list = ['score']\n",
    "\n",
    "## Create derived target metrics\n",
    "#For each file\n",
    "filelist = ['s30-b32-l128', 's30-b128-l128', 's30-b32-l512', 's30-b128-l512', 's30-b32-l1024','s30-b128-l1024']\n",
    "#target_list = ['ts', 'GPUBusy', 'VALUBusy', 'MemUnitBusy', 'VALUUtilization', 'ratio1', 'ratio2']\n",
    "target_list = ['ts']\n",
    "cumulative_index = 0\n",
    "for model_index in range(len(df_dict_updated)):#range(len(workloads)): #For each model\n",
    "    df_original2 = df_dict_updated[model_index]\n",
    "    for target in target_list:\n",
    "        df_original3 = df_original2[feature_list[model_index]]\n",
    "        ##Make sure to fill up all Nan values with 0\n",
    "        df_original3 = df_original3.fillna(0)\n",
    "\n",
    "        #Add a target at a time to original3\n",
    "        df_original3[target] = df_original2[target]\n",
    "\n",
    "        #\n",
    "        outfilename = output_prefix[ind] + '_' + target +'_'+filelist[model_index]+'.csv'\n",
    "        #print('Generating ' + outfilename + '...')\n",
    "        generate_dash_data_format(df_original3, feature_list, target, region_list, outfilename, \"KernelName\")\n",
    "        ## TODO: PASS the following function feature_list[ind] and region_list[ind]\n",
    "        #generate_dash_data_format(df_original3, feature_list[model_index], target, region_list[model_index], outfilename, \"KernelName\")\n",
    "        print('    - ', filelist[model_index])\n",
    "        #generate_config_block_for_this_input(filelist[model_index], outfilename, target)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## AMD Q2 -- feature compression and feature correaltion analysis --- \n",
    "## input: df_dict_updated --> each model has all input combined into it.\n",
    "colors=['red', 'blue', 'green', 'orange']\n",
    "\n",
    "for model_index in range(len(df_dict_updated)):#range(len(workloads)): #For each model\n",
    "    df_original2 = df_dict_updated[model_index]\n",
    "    plot_df(df_original2, 'ts', colors[model_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_df(input_df, target, c):\n",
    "    fig, ax = plt.subplots()\n",
    "    input_df[target].plot(ax=ax, kind='bar', color = c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns info sieve output with nh components    \n",
    "def infoSieveX(X,nh):\n",
    "        identifier= 'Using Information Sieve %d Components'%nh\n",
    "        s = linearsieve.Sieve(n_hidden=nh, verbose=0).fit(X + 0.05*np.random.randn(X.shape[0],X.shape[1]))\n",
    "        X_lat = s.transform(X) \n",
    "        return X_lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df_dict_updated[0]\n",
    "col_std_list = [ col for col in df2.columns if '_std' in col]\n",
    "for c in col_std_list:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('in.txt', sep=\" \")\n",
    "file1 = open(\"event_names_amd.txt\",\"w\")\n",
    "\n",
    "for k in df:\n",
    "    #print (k)\n",
    "    file1.write(k+\"\\n\")\n",
    "file1.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Special processing block for Q2: AMD report\n",
    "##Input: res_imp_rnn.csv file which contains resource importance for all the kernels. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fom_lstm_output(filename):\n",
    "\n",
    "    ###### Read and parse FOM for LSTM / RNN benchmark's output\n",
    "    total = 0.0\n",
    "    count = 0\n",
    "    with open(filename, \"r\") as fom_file:\n",
    "        read_next_line = 0\n",
    "        for line in fom_file:\n",
    "    #         print(line)\n",
    "            if read_next_line == 1: #If I am supposed to read this line \n",
    "                total += np.float((line.split())[4])\n",
    "                read_next_line = 0\n",
    "                count += 1\n",
    "            elif \"Forward + Backward\" in line:\n",
    "                read_next_line = 1\n",
    "    return 1.0/(total/count)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_fom_lstm_output('/Users/tanzima/Research/AMD/DATA/mi-50/DATA-aac-july21/results')\n",
    "import os\n",
    "model_names = ['basic_lstm', 'rnn', 'lstm']\n",
    "for filename in os.listdir('/Users/tanzima/Research/AMD/DATA/mi-50/DATA-aac-july21/results'):\n",
    "    print (filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
